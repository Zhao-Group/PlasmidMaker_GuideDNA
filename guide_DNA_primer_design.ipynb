{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All restriction enzymes are palindromic\n",
      "Use wild-type + mutant PfAgo for plasmid assembly\n",
      "Guides obtained successfully for 17kb-17p_modified.dna\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import itertools\n",
    "import glob\n",
    "from functools import reduce\n",
    "from itertools import groupby\n",
    "import primer3\n",
    "\n",
    "#Snapgene module\n",
    "from snapgene_reader import snapgene_file_to_dict, snapgene_file_to_seqrecord\n",
    "\n",
    "#Functions\n",
    "def band_filter(distance):\n",
    "    accuracy_of_fragment_analzyer = 0.1\n",
    "    flag = 1\n",
    "\n",
    "    if max(distance) > 9500:\n",
    "        flag = flag*0\n",
    "    else:\n",
    "        flag = flag*1\n",
    "    \n",
    "    if min(distance) < 100:\n",
    "        flag = flag*0\n",
    "    else:\n",
    "        flag = flag*1\n",
    "    \n",
    "    for i in range(len(distance)-1):\n",
    "        band_size_diff = distance[i+1] - distance[i]\n",
    "        if band_size_diff > accuracy_of_fragment_analzyer*distance[i]:\n",
    "            flag = flag*1\n",
    "        else:\n",
    "            flag = flag*0\n",
    "\n",
    "    if flag == 1:\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "def list_sort(curr_list): \n",
    "    curr_list.sort(key = lambda x: x[0]) \n",
    "    return pd.DataFrame(curr_list,columns = ['fragment_number','dna_sequence'])\n",
    "\n",
    "def percent_gc(seq):\n",
    "    gc = 0\n",
    "    for i in range(len(seq)):\n",
    "        if seq[i] == 'G' or seq[i]=='g':\n",
    "            gc = gc + 1\n",
    "        if seq[i] == 'C' or seq[i]=='c':\n",
    "            gc = gc + 1\n",
    "\n",
    "    GC = gc*100/len(seq) \n",
    "    return GC\n",
    "\n",
    "def revcom(seq):\n",
    "    answer=''\n",
    "    for i in range(0,len(seq)):       \n",
    "        if seq[i]== 'A' or seq[i]== 'a':\n",
    "            answer ='T'+answer\n",
    "        elif seq[i]=='C' or seq[i]=='c':\n",
    "            answer ='G'+answer\n",
    "        elif seq[i]=='G' or seq[i]=='g':\n",
    "            answer ='C'+answer\n",
    "        elif seq[i]=='T' or seq[i]=='t':\n",
    "            answer ='A'+answer\n",
    "    return answer\n",
    "\n",
    "def palindrome(n):\n",
    "    return n == n[::-1]\n",
    "\n",
    "def sim_score(seq1,seq2):\n",
    "    return sum (seq1[i] == seq2[i] for i in range(len(seq1)))\n",
    "\n",
    "def freq_count(x):\n",
    "    unique, counts = np.unique(x, return_counts=True)\n",
    "    y = np.asarray((unique, counts)).T[::-1] \n",
    "    return y\n",
    "\n",
    "def comb_off_target(a,b):\n",
    "    c = []\n",
    "    for i in range(len(a)):\n",
    "        c_flag = 0\n",
    "        for j in range(len(b)):\n",
    "            if a[i][0] == b[j][0]:\n",
    "                c.append([a[i][0],a[i][1] + b[j][1]])   \n",
    "                c_flag = 1\n",
    "        if c_flag == 0:\n",
    "            c.append([a[i][0],a[i][1]])\n",
    "\n",
    "    for i in range(len(b)):\n",
    "        c_flag = 0\n",
    "        for j in range(len(a)):\n",
    "            if b[i][0] == a[j][0]:\n",
    "                c_flag = 1\n",
    "        if c_flag == 0:\n",
    "            c.append([b[i][0],b[i][1]])      \n",
    "    \n",
    "    return c\n",
    "\n",
    "def off_target_check(x,hm_score):\n",
    "    flag_ot = 1\n",
    "    if x[0][0] == 22:\n",
    "        if x[0][1] > 1:\n",
    "            flag_ot = flag_ot*0\n",
    "        else:\n",
    "            flag_ot = flag_ot*1\n",
    "    if x[1][0] >= hm_score: \n",
    "        flag_ot = flag_ot*0\n",
    "    else:\n",
    "        flag_ot = flag_ot*1\n",
    "        \n",
    "    return flag_ot\n",
    "\n",
    "def three_frag_score(seq1,seq2,large_3f_score,mid_3f_score):\n",
    "    if sim_score(seq1,seq2) >= large_3f_score: \n",
    "        mid_seq1 = seq1[8:14]\n",
    "        mid_seq2 = seq2[8:14]\n",
    "        if sim_score(mid_seq1,mid_seq2) >= mid_3f_score:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def mismatch_score(seq1,seq2):\n",
    "    score = 0\n",
    "    for a in range(len(seq1)):\n",
    "        if seq1[a] == seq2[a]:\n",
    "            score = score + (5.5-a)*(5.5-a)\n",
    "        elif seq1[a] == 'T' and seq2[a] == 'C':\n",
    "            score = score + 0.75*(5.5-a)*(5.5-a)\n",
    "        elif seq1[a] == 'G' and seq2[a] == 'A':\n",
    "            score = score + 0.75*(5.5-a)*(5.5-a)\n",
    "            \n",
    "    return score\n",
    "\n",
    "def overlap(a, b):\n",
    "    return max(i for i in range(len(b)+1) if a.endswith(b[:i]))\n",
    "\n",
    "def getTM(seq1, seq2):\n",
    "    tm1 = primer3.calcTm(seq1)\n",
    "    tm2 = primer3.calcTm(seq2)\n",
    "\n",
    "    return [tm1, tm2]\n",
    "\n",
    "def combine_strings(x):\n",
    "    for perm in permutations(x):\n",
    "        linked = [perm[i][:-5] for i in range(len(perm)-1) \n",
    "                               if perm[i][-5:]==perm[i+1][:5]]\n",
    "        if len(perm)-1==len(linked):\n",
    "            return \"\".join(linked)+perm[-1]\n",
    "    return None\n",
    "\n",
    "def CntSubstr(pattern, string):\n",
    "    a = [m.start() for m in re.finditer(\n",
    "        '(?={0})'.format(re.escape(pattern)), string)]\n",
    "    return a[0]\n",
    "\n",
    "def is_valid_guide(seq1):\n",
    "    flag = 1\n",
    "    curr_target = seq1\n",
    "    guide = curr_target[1:23]\n",
    "    guide_u = revcom(curr_target[1:15])\n",
    "    guide_l = curr_target[9:23]\n",
    "    \n",
    "    #Intrafragment Analysis\n",
    "    #criteria: GC content\n",
    "    if gc_stringency == 0:\n",
    "        gc_crit = -15\n",
    "    elif gc_stringency == 1:\n",
    "        gc_crit = -10\n",
    "    elif gc_stringency == 2:\n",
    "        gc_crit = -5\n",
    "    else:\n",
    "        gc_crit = 0 \n",
    "        \n",
    "    if pfago_flag == 0:\n",
    "        gc = percent_gc(curr_target) \n",
    "        if gc > 15 and gc <= 60 + gc_crit: #45,50,55,60\n",
    "            flag = flag*1\n",
    "        else: \n",
    "            flag = flag*0\n",
    "\n",
    "    else:\n",
    "        gc = percent_gc(curr_target)\n",
    "        if gc > 30 and gc <= 75 + gc_crit:\n",
    "            flag = flag*1\n",
    "        else: \n",
    "            flag = flag*0\n",
    "        \n",
    "    if pfago_flag == 0:\n",
    "        gc = percent_gc(guide_u)\n",
    "        if gc > 15 and gc <= 65 + gc_crit: #50,55,60,65\n",
    "            flag = flag*1\n",
    "        else: \n",
    "            flag = flag*0\n",
    "\n",
    "    else:\n",
    "        gc = percent_gc(guide_u)\n",
    "        if gc > 30 and gc <= 75 + gc_crit:\n",
    "            flag = flag*1\n",
    "        else: \n",
    "            flag = flag*0\n",
    "    \n",
    "    if pfago_flag == 0:\n",
    "        gc = percent_gc(guide_l)\n",
    "        if gc > 15 and gc <= 65 + gc_crit:\n",
    "            flag = flag*1\n",
    "        else: \n",
    "            flag = flag*0\n",
    "\n",
    "    else:\n",
    "        gc = percent_gc(guide_l)\n",
    "        if gc > 30 and gc <= 75 + gc_crit:\n",
    "            flag = flag*1\n",
    "        else: \n",
    "            flag = flag*0\n",
    "    \n",
    "    if flag == 0:\n",
    "        #print('Problem due to GC content')\n",
    "        return False\n",
    "    \n",
    "    #criteria: G-quadraplex or more than 5 consecutive A or Ts \n",
    "    ## G-quadraplex\n",
    "    if curr_target.find('GGGG') >-1: \n",
    "        flag = flag*0\n",
    "    else: \n",
    "        flag = flag*1\n",
    "\n",
    "    if curr_target.find('CCCC') >-1:\n",
    "        flag = flag*0\n",
    "    else: \n",
    "        flag = flag*1\n",
    "\n",
    "    ##more than 5 consecutive A or Ts \n",
    "    if curr_target.find('A'*AT_stringency) >-1:\n",
    "        flag = flag*0\n",
    "    else: \n",
    "        flag = flag*1\n",
    "\n",
    "    if curr_target.find('T'*AT_stringency) >-1:\n",
    "        flag = flag*0\n",
    "    else: \n",
    "        flag = flag*1\n",
    "    \n",
    "    if flag == 0:\n",
    "        #print('Problem due to GGGG/TTTT/AAAAAA/TTTTTT')\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    #Interfragment Analysis\n",
    "    #Off-target scores[Constraint 1]: on 22 bp\n",
    "    g_off_target_str_plasmid_score = []\n",
    "    for o_t in range(len(off_target_str_plasmid_seq)):\n",
    "        g_off_target_str_plasmid_score.append(sim_score(guide,off_target_str_plasmid_seq[o_t]))\n",
    "    \n",
    "     \n",
    "    g_off_target_op_str_plasmid_score = []\n",
    "    for o_t in range(len(off_target_op_str_plasmid_seq)):\n",
    "        g_off_target_op_str_plasmid_score.append(sim_score(guide,off_target_op_str_plasmid_seq[o_t]))\n",
    "\n",
    "    g_str_freq_count = freq_count(g_off_target_str_plasmid_score)\n",
    "    g_op_str_freq_count = freq_count(g_off_target_op_str_plasmid_score)\n",
    "    g_freq_count = comb_off_target(g_str_freq_count,g_op_str_freq_count)\n",
    "\n",
    "    if off_target_check(g_freq_count,hm_score) == 1:\n",
    "        flag = flag*1\n",
    "    else:\n",
    "        flag = flag*0\n",
    "    \n",
    "    if flag == 0:\n",
    "        #print('Problem due to homology score')\n",
    "        return False\n",
    "    \n",
    "    #Off-target scores[Constraint 2]: Three fragment check\n",
    "    g_3_frag_target_str_plasmid_score = []\n",
    "    for f_t in range(len(off_target_str_plasmid_seq)):\n",
    "        g_3_frag_target_str_plasmid_score.append(three_frag_score(guide,off_target_str_plasmid_seq[f_t],large_3f_score,mid_3f_score))\n",
    "\n",
    "    g_3_frag_target_op_str_plasmid_score = []\n",
    "    for f_t in range(len(off_target_op_str_plasmid_seq)):\n",
    "        g_3_frag_target_op_str_plasmid_score.append(three_frag_score(guide,off_target_op_str_plasmid_seq[f_t],large_3f_score,mid_3f_score))\n",
    "\n",
    "    if len(g_3_frag_target_str_plasmid_score) - sum(g_3_frag_target_str_plasmid_score) < 2:\n",
    "        flag = flag*1\n",
    "    else:\n",
    "        flag = flag*0\n",
    "\n",
    "    if len(g_3_frag_target_op_str_plasmid_score) - sum(g_3_frag_target_op_str_plasmid_score) < 2:\n",
    "        flag = flag*1\n",
    "    else:\n",
    "        flag = flag*0\n",
    "    \n",
    "    if flag == 0:\n",
    "        #print('Problem due to 3 frag score')\n",
    "        return False\n",
    "    \n",
    "    #palindromic sticky ends\n",
    "    sticky_end_target = curr_target[6:18]\n",
    "    if palindrome(sticky_end_target):\n",
    "        flag = flag*0\n",
    "    else:\n",
    "        flag = flag*1 \n",
    "        \n",
    "    #valid guide or not\n",
    "    if flag == 1:\n",
    "        return True\n",
    "    else: \n",
    "        #print('Problem due to sticky ends')\n",
    "        return False\n",
    "\n",
    "#Restriction Enzyme for Verification\n",
    "df = pd.read_excel(\"common_re_list.xlsx\")\n",
    "re_site = df.to_numpy()\n",
    "count = 0\n",
    "for re_i in range(1,np.shape(re_site)[0]):\n",
    "    curr_re_seq = re_site[re_i,0]\n",
    "    if curr_re_seq == revcom(curr_re_seq):\n",
    "        count = count + 1\n",
    "        \n",
    "if count == len(re_site)-1:\n",
    "    print(\"All restriction enzymes are palindromic\") \n",
    "    \n",
    "final_re_count = 0\n",
    "working_plasmid_count = 0\n",
    "common_final_re_df_index = ['RE Combinations']\n",
    "final_fragments = []\n",
    "final_interm_fragments = []\n",
    "for files in glob.glob(\"*.dna\"):\n",
    "    snap_file = files  \n",
    "    \n",
    "    #reading snap_gene_file\n",
    "    dictionary = snapgene_file_to_dict(snap_file)\n",
    "    seqrecord = snapgene_file_to_seqrecord(snap_file)\n",
    "    filename = snap_file.split('.')[0] + '.xlsx'\n",
    "\n",
    "    count = 0\n",
    "    data_stat = []\n",
    "    for i in range(len(dictionary['features'])):\n",
    "        if 'fragment' in dictionary['features'][i]['name']:\n",
    "            count = count + 1\n",
    "            frag_start, frag_end = next(iter(dictionary['features'][i]['segments'][0].items()))[1].split('-')\n",
    "            f_start = int(frag_start)-1\n",
    "            f_end = int(frag_end)\n",
    "            if f_start < f_end:\n",
    "                curr_seq = dictionary['seq'][f_start:f_end]\n",
    "            else:\n",
    "                curr_seq = dictionary['seq'][f_start:len(dictionary['seq'])] + dictionary['seq'][0:f_end]\n",
    "            data_stat.append([int(dictionary['features'][i]['name'].replace('fragment','')),curr_seq])\n",
    "            \n",
    "        if 'Fragment' in dictionary['features'][i]['name']:\n",
    "            count = count + 1\n",
    "            frag_start, frag_end = next(iter(dictionary['features'][i]['segments'][0].items()))[1].split('-')\n",
    "            f_start = int(frag_start)-1\n",
    "            f_end = int(frag_end)\n",
    "            if f_start < f_end:\n",
    "                curr_seq = dictionary['seq'][f_start:f_end]\n",
    "            else:\n",
    "                curr_seq = dictionary['seq'][f_start:len(dictionary['seq'])] + dictionary['seq'][0:f_end]\n",
    "            data_stat.append([int(dictionary['features'][i]['name'].replace('Fragment','')),curr_seq])\n",
    "\n",
    "    df = list_sort(data_stat)\n",
    "    insert_order_specified = np.array(df.fragment_number)\n",
    "    sequences_specified = np.array(df.dna_sequence)\n",
    "\n",
    "    order = insert_order_specified.argsort()\n",
    "    insert_order = insert_order_specified[order]\n",
    "    sequences_case = sequences_specified[order]\n",
    "\n",
    "    pre_sequences = []\n",
    "    for i in range(len(sequences_case)):\n",
    "        pre_sequences.append(sequences_case[i].upper())\n",
    "    \n",
    "    del_index = []\n",
    "    merge_flag = 0\n",
    "    merging_tm_template = []\n",
    "    for i in range(len(pre_sequences)):\n",
    "        if len(pre_sequences[i])<80:\n",
    "            del_index.append(i)\n",
    "            print('fragment less than 80 bp')\n",
    "            merge_flag = 1\n",
    "            if len(pre_sequences[i])%2 == 0:\n",
    "                first_half = pre_sequences[i][0:len(pre_sequences[i])//2]\n",
    "                second_half = pre_sequences[i][len(pre_sequences[i])//2:]\n",
    "            else:\n",
    "                first_half = pre_sequences[i][0:len(pre_sequences[i])//2]\n",
    "                second_half = pre_sequences[i][len(pre_sequences[i])//2:]\n",
    "\n",
    "            if i==0:\n",
    "                merging_tm_template.append([len(pre_sequences)-1,i+1])     \n",
    "\n",
    "                pre_sequences[len(pre_sequences)-1] = pre_sequences[len(pre_sequences)-1] + first_half\n",
    "                pre_sequences[i+1] = second_half + pre_sequences[i+1]\n",
    "\n",
    "            elif i==len(pre_sequences)-1: \n",
    "                merging_tm_template.append([i-1,0])   \n",
    "\n",
    "                pre_sequences[i-1] = pre_sequences[i-1] + first_half\n",
    "                pre_sequences[0] =  second_half + pre_sequences[0]\n",
    "            else:\n",
    "                merging_tm_template.append([i-1,i+1])   \n",
    "\n",
    "                pre_sequences[i-1] = pre_sequences[i-1] + first_half\n",
    "                pre_sequences[i+1] = second_half + pre_sequences[i+1]\n",
    "\n",
    "    sequences = []\n",
    "    if len(del_index) > 0:\n",
    "        for i in range(len(pre_sequences)):\n",
    "            if len(pre_sequences[i]) >= 80:\n",
    "                sequences.append(pre_sequences[i])\n",
    "    else:\n",
    "        sequences = pre_sequences\n",
    "\n",
    "    #Restoring presequence (by removing if there was any addition)\n",
    "    if merge_flag == 1:\n",
    "        pre_sequences = []\n",
    "        for i in range(len(sequences_case)):\n",
    "            pre_sequences.append(sequences_case[i].upper())\n",
    "\n",
    "    ##Complete Plasmid Sequence\n",
    "    for p_i in range(len(sequences)):\n",
    "        if p_i == 0:\n",
    "            plasmid_seq = sequences[p_i]\n",
    "        else:\n",
    "            plasmid_seq = plasmid_seq + sequences[p_i]\n",
    "\n",
    "    re_plasmid_seq = plasmid_seq + sequences[0][0:7]\n",
    "    str_plasmid_seq = plasmid_seq + sequences[0][0:21] #to ensure we analyze circular plasmid \n",
    "    op_str_plasmid_seq = revcom(str_plasmid_seq)\n",
    "\n",
    "    #Off-target library\n",
    "    off_target_str_plasmid_seq = []\n",
    "    for i in range(len(plasmid_seq)):\n",
    "        off_target_str_plasmid_seq.append(str_plasmid_seq[0+i:22+i])\n",
    "    \n",
    "    off_target_op_str_plasmid_seq = []\n",
    "    for i in range(len(plasmid_seq)):\n",
    "        off_target_op_str_plasmid_seq.append(op_str_plasmid_seq[0+i:22+i])\n",
    "\n",
    "    #Guide Library\n",
    "    search_space = '80 bp fragment'\n",
    "    guide_24bp = []\n",
    "    pre_mmlig_guide = []\n",
    "    for i in range(len(sequences)):\n",
    "        guide_24bp.append('guide for joint'+str(i))\n",
    "        pre_mmlig_guide.append([i,'guide for joint'+str(i)])\n",
    "        if i == 0:\n",
    "            search_space = np.vstack((search_space,sequences[len(sequences)-1][-40:]+sequences[i][0:40]))\n",
    "        else:\n",
    "            search_space = np.vstack((search_space,sequences[i-1][-40:]+sequences[i][0:40]))\n",
    "\n",
    "    for i in range(57):\n",
    "        curr_guides = []\n",
    "        for j in range(len(sequences)):\n",
    "            curr_guides.append(search_space[j+1][0][0+i:24+i])\n",
    "\n",
    "        guide_24bp = np.vstack((guide_24bp,curr_guides))\n",
    "\n",
    "    #guide library centered\n",
    "    c_guide_24bp = guide_24bp[0,:]\n",
    "    k = 29\n",
    "    for i in range(1,np.shape(guide_24bp)[0]):\n",
    "        c_guide_24bp = np.vstack((c_guide_24bp,guide_24bp[k,:]))\n",
    "        if i%2 == 0:\n",
    "            k = k - i\n",
    "        else:\n",
    "            k = k + i\n",
    "\n",
    "    guide_library = np.asarray(c_guide_24bp)\n",
    "\n",
    "    #Step 1: measuring fragments and guide search space GC and deciding which PfAgo to use\n",
    "    inserts_percent_gc = []\n",
    "    for i in range(len(sequences)):\n",
    "        inserts_percent_gc.append(percent_gc(sequences[i]))\n",
    "\n",
    "    guide_search_space_gc = []\n",
    "    for i in range(1, np.shape(search_space)[0]):\n",
    "        guide_search_space_gc.append(percent_gc(search_space[i][0]))\n",
    "    \n",
    "    if sum(i > 57 for i in inserts_percent_gc)/len(inserts_percent_gc) > 0.5:\n",
    "        if any(gc_ss > 65 for gc_ss in guide_search_space_gc):\n",
    "            pfago_flag = 1\n",
    "            print('Use mutant PfAgo for plasmid assembly')\n",
    "        else:\n",
    "            pfago_flag = 0\n",
    "            print('Use wild-type + mutant PfAgo for plasmid assembly')\n",
    "    else:\n",
    "        pfago_flag = 0\n",
    "        print('Use wild-type + mutant PfAgo for plasmid assembly')\n",
    "    \n",
    "    param_space = []\n",
    "    for k in range(2):\n",
    "        for i in range(3):\n",
    "            for j in range(i,i+2):\n",
    "                param_space.append([15+i,13+j,5+k])\n",
    "\n",
    "    for at_repeats_i in range(2):\n",
    "        for gc_content_i in range(4):\n",
    "            hm_score = param_space[0][0]\n",
    "            large_3f_score = param_space[0][1]\n",
    "            mid_3f_score = param_space[0][2]\n",
    "            score_param_space = 1\n",
    "\n",
    "            insert_target_found = []\n",
    "            m_check = []\n",
    "            for i in range(len(sequences)):\n",
    "                insert_target_found.append(False)\n",
    "                m_check.append(-1)\n",
    "\n",
    "            targets_found = False\n",
    "\n",
    "            final_guide = []\n",
    "            AT_stringency = 5 + at_repeats_i\n",
    "            gc_stringency = gc_content_i\n",
    "\n",
    "            while not targets_found:\n",
    "                for m in range(len(sequences)):\n",
    "                    if not insert_target_found[m]:\n",
    "                        for i in range(1,np.shape(guide_library)[0]):\n",
    "                            if i > m_check[m]:\n",
    "                                target = guide_library[i,m]\n",
    "                                m_check[m] = i\n",
    "\n",
    "                                # All criteria except mismatch ligation are checked here\n",
    "                                if is_valid_guide(target):       \n",
    "                                    pre_mmlig_guide[m][1] = target\n",
    "                                    insert_target_found[m] = True\n",
    "                                    break\n",
    "\n",
    "                if all(insert_target_found):\n",
    "                    targets_found = True\n",
    "                else: \n",
    "                    targets_found = False \n",
    "\n",
    "                #mismatch ligation check\n",
    "                if targets_found:\n",
    "                    sticky_end = []\n",
    "                    for q in range(len(sequences)):\n",
    "                        sticky_end.append(pre_mmlig_guide[q][1][6:18])\n",
    "                        sticky_end.append(revcom(pre_mmlig_guide[q][1][6:18]))\n",
    "\n",
    "                    mmlig_matrix = np.zeros([len(sticky_end),len(sticky_end)])\n",
    "                    for mml1 in range(len(sticky_end)):\n",
    "                        for mml2 in range(len(sticky_end)):\n",
    "                            if mml1 != mml2:\n",
    "                                mmlig_matrix[mml1,mml2] = mismatch_score(sticky_end[mml1],sticky_end[mml2])\n",
    "\n",
    "                    if np.all(mmlig_matrix < 100): \n",
    "                        final_guide = pre_mmlig_guide\n",
    "                    else:\n",
    "                        max_ind = np.unravel_index(np.argmax(mmlig_matrix, axis=None), mmlig_matrix.shape)\n",
    "                        m_mml1 = max_ind[0]//2 \n",
    "                        m_mml2 = max_ind[1]//2 \n",
    "                        if m_mml1 == m_mml2:\n",
    "                            m_mml = m_mml1\n",
    "                        else:\n",
    "                            if m_check[m_mml1] < m_check[m_mml2]:\n",
    "                                m_mml = m_mml1\n",
    "                            else:\n",
    "                                m_mml = m_mml2\n",
    "                        targets_found = False\n",
    "                        insert_target_found[m_mml] = False\n",
    "\n",
    "                if len(param_space) > score_param_space:\n",
    "                    if any(x==57 for x in m_check):\n",
    "                        hm_score = param_space[score_param_space][0]\n",
    "                        large_3f_score = param_space[score_param_space][1]\n",
    "                        mid_3f_score = param_space[score_param_space][2]\n",
    "                        score_param_space = score_param_space + 1\n",
    "                        insert_target_found = [] \n",
    "                        m_check = []\n",
    "                        for i in range(len(sequences)):\n",
    "                            insert_target_found.append(False)\n",
    "                            m_check.append(-1)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            if targets_found:\n",
    "                break\n",
    "\n",
    "        if targets_found:\n",
    "            break\n",
    "            \n",
    "    if not targets_found:\n",
    "        print('No guides can be found for ' + snap_file)\n",
    "        to_find_primer_flag = 0\n",
    "    else:\n",
    "        print('Guides obtained successfully for ' + snap_file)\n",
    "        to_find_primer_flag = 1\n",
    "        working_plasmid_count = working_plasmid_count + 1\n",
    "        \n",
    "    ini_tm_len = 18\n",
    "    if to_find_primer_flag == 1:\n",
    "        \n",
    "        #Small fragment merging primers\n",
    "        merging_primers = ['Temp Number', 'F Primer', 'R Primer','Extension Time (in secs)', 'Template Length']\n",
    "        if merge_flag == 1:\n",
    "            for i in range(np.shape(merging_tm_template)[0]):\n",
    "                cb_region = ['Temp Number', 'F Primer', 'R Primer','Extension Time (in secs)']\n",
    "                for j in range(np.shape(merging_tm_template)[1]):\n",
    "                    curr_temp = merging_tm_template[i][j]\n",
    "\n",
    "                    tm_flag = 0\n",
    "                    \n",
    "                    ini_mg_fp_seq = pre_sequences[curr_temp][0:ini_tm_len]\n",
    "                    if percent_gc(ini_mg_fp_seq) < 30:\n",
    "                        tm_len = 25\n",
    "                    elif percent_gc(ini_mg_fp_seq) > 70:\n",
    "                        tm_len = 18\n",
    "                    else:\n",
    "                        tm_len = 20\n",
    "                            \n",
    "                    mg_fp_seq = pre_sequences[curr_temp][0:tm_len]\n",
    "                    \n",
    "                    ini_mg_rp_seq = revcom(pre_sequences[curr_temp][-ini_tm_len:])\n",
    "                    if percent_gc(ini_mg_rp_seq) < 30:\n",
    "                        tm_len = 25\n",
    "                    elif percent_gc(ini_mg_rp_seq) > 70:\n",
    "                        tm_len = 18\n",
    "                    else:\n",
    "                        tm_len = 20\n",
    "                        \n",
    "                    mg_rp_seq = revcom(pre_sequences[curr_temp][-tm_len:])\n",
    "                            \n",
    "                    while tm_flag == 0:\n",
    "                        ta_tm_values = getTM(mg_fp_seq,mg_rp_seq)\n",
    "                        if np.abs(ta_tm_values[0]-ta_tm_values[1]) > 2:\n",
    "                            tm_flag = 0\n",
    "                            tm_len = tm_len + 1 \n",
    "                            if ta_tm_values[0] - ta_tm_values[1] > 0:\n",
    "                                mg_rp_seq = revcom(pre_sequences[curr_temp][-tm_len:])\n",
    "                            else:\n",
    "                                mg_fp_seq = pre_sequences[curr_temp][0:tm_len]\n",
    "                        else:\n",
    "                            tm_flag = 1\n",
    "                            cb_region = np.vstack((cb_region, [curr_temp, mg_fp_seq, mg_rp_seq, np.round(len(pre_sequences[curr_temp])*(30/1000),2)]))\n",
    "\n",
    "                #dividing small fragment < 80 bp and adding it to adjacent fragments\n",
    "                if cb_region[1][0] == len(pre_sequences) - 1:\n",
    "                    small_insert_seq = pre_sequences[len(pre_sequences) - 1]\n",
    "\n",
    "                elif cb_region[1][0] == 0:\n",
    "                    small_insert_seq = pre_sequences[0]\n",
    "\n",
    "                else:\n",
    "                    small_insert_seq = pre_sequences[int(cb_region[1][0]) + 1]\n",
    "\n",
    "                first_half = small_insert_seq[0:len(small_insert_seq)//2]\n",
    "                second_half = small_insert_seq[len(small_insert_seq)//2:]\n",
    "\n",
    "                for i in range(2):\n",
    "                    if i == 0: \n",
    "                        merging_primers = np.vstack((merging_primers,[cb_region[i+1][0],cb_region[i+1][1],revcom(first_half) + cb_region[1][2],cb_region[i+1][3],len(first_half)+len(pre_sequences[int(cb_region[i+1][0])])]))\n",
    "                    else:\n",
    "                        merging_primers = np.vstack((merging_primers,[cb_region[i+1][0],second_half + cb_region[2][1],cb_region[i+1][2],cb_region[i+1][3],len(second_half)+len(pre_sequences[int(cb_region[i+1][0])])]))\n",
    "\n",
    "        #Primers for One pot PCR fragments\n",
    "        PCR_primers = ['Temp Number', 'F Primer', 'R Primer','Extension Time (in secs)', 'Template Length']\n",
    "        for i in range(np.shape(final_guide)[0]):\n",
    "            cb_region = ['Temp Number', 'F Primer', 'R Primer','Extension Time (in secs)']\n",
    "            if i == np.shape(final_guide)[0] - 1:\n",
    "                curr_guide_1 = final_guide[i][1]\n",
    "                curr_guide_2 = final_guide[0][1]\n",
    "            else:\n",
    "                curr_guide_1 = final_guide[i][1]\n",
    "                curr_guide_2 = final_guide[i+1][1]\n",
    "\n",
    "            f_rule = 0\n",
    "            r_rule = 0\n",
    "\n",
    "            #F primer\n",
    "            if i == 0:\n",
    "                f_temp_left = sequences[len(sequences) - 1]\n",
    "                f_temp_right = sequences[i]\n",
    "            else:\n",
    "                f_temp_left = sequences[i-1]\n",
    "                f_temp_right = sequences[i]\n",
    "\n",
    "            if curr_guide_1 in f_temp_left:\n",
    "                fg_ind  = f_temp_left.index(curr_guide_1)\n",
    "                overhang_f = f_temp_left[fg_ind:len(f_temp_left)]\n",
    "                \n",
    "                if percent_gc(f_temp_right[0:ini_tm_len]) < 30 :\n",
    "                    tm_len = 25\n",
    "                elif percent_gc(f_temp_right[0:ini_tm_len]) > 70:\n",
    "                    tm_len = 18\n",
    "                else:\n",
    "                    tm_len = 20\n",
    "                            \n",
    "                f_primer = f_temp_right[0:tm_len]\n",
    "                f_rule = 1\n",
    "\n",
    "            elif curr_guide_1 in f_temp_right:\n",
    "                fg_ind = f_temp_right.index(curr_guide_1)\n",
    "                \n",
    "                if percent_gc(f_temp_right[fg_ind:fg_ind+ini_tm_len]) < 30 :\n",
    "                    tm_len = 25\n",
    "                elif percent_gc(f_temp_right[fg_ind:fg_ind+ini_tm_len]) > 70:\n",
    "                    tm_len = 18\n",
    "                else:\n",
    "                    tm_len = 20\n",
    "                            \n",
    "                f_primer = f_temp_right[fg_ind:fg_ind+tm_len]\n",
    "                overhang_f = ''\n",
    "                f_rule = 2\n",
    "\n",
    "            else: #present on both fragments\n",
    "                join_temp = f_temp_left + f_temp_right\n",
    "                fg_ind = join_temp.index(curr_guide_1)\n",
    "                overhang_f = f_temp_left[fg_ind:len(f_temp_left)]\n",
    "                \n",
    "                if percent_gc(f_temp_right[0:ini_tm_len]) < 30 :\n",
    "                    tm_len = 25\n",
    "                elif percent_gc(f_temp_right[0:ini_tm_len]) > 70:\n",
    "                    tm_len = 18\n",
    "                else:\n",
    "                    tm_len = 20\n",
    "                    \n",
    "                f_primer = f_temp_right[0:tm_len]\n",
    "                f_rule = 3\n",
    "\n",
    "            #R primer\n",
    "            if i == len(sequences) - 1:\n",
    "                r_temp_left = sequences[len(sequences) - 1]\n",
    "                r_temp_right = sequences[0]\n",
    "            else:\n",
    "                r_temp_left = sequences[i]\n",
    "                r_temp_right = sequences[i+1]\n",
    "\n",
    "            if curr_guide_2 in r_temp_left:\n",
    "                rg_ind  = r_temp_left.index(curr_guide_2)\n",
    "                \n",
    "                if percent_gc(revcom(r_temp_left[rg_ind+24-ini_tm_len:rg_ind+24])) < 30 :\n",
    "                    tm_len = 25\n",
    "                elif percent_gc(revcom(r_temp_left[rg_ind+24-ini_tm_len:rg_ind+24])) > 70:\n",
    "                    tm_len = 18\n",
    "                else:\n",
    "                    tm_len = 20\n",
    "                        \n",
    "                r_primer = revcom(r_temp_left[rg_ind+24-tm_len:rg_ind+24])\n",
    "                overhang_r = ''\n",
    "                r_rule = 1\n",
    "\n",
    "            elif curr_guide_2 in r_temp_right:\n",
    "                rg_ind  = r_temp_right.index(curr_guide_2)\n",
    "                \n",
    "                if percent_gc(revcom(r_temp_left[-ini_tm_len:])) < 30 :\n",
    "                    tm_len = 25\n",
    "                elif percent_gc(revcom(r_temp_left[-ini_tm_len:])) > 70:\n",
    "                    tm_len = 18\n",
    "                else:\n",
    "                    tm_len = 20\n",
    "                    \n",
    "                r_primer = revcom(r_temp_left[-tm_len:])\n",
    "                overhang_r = revcom(r_temp_right[0:rg_ind+24])\n",
    "                r_rule = 2\n",
    "\n",
    "            else: #present on both fragments\n",
    "                join_temp = r_temp_left + r_temp_right\n",
    "                rg_ind = join_temp.index(curr_guide_2)\n",
    "                \n",
    "                if percent_gc(revcom(r_temp_left[-ini_tm_len:])) < 30 :\n",
    "                    tm_len = 25\n",
    "                elif percent_gc(revcom(r_temp_left[-ini_tm_len:])) > 70:\n",
    "                    tm_len = 18\n",
    "                else:\n",
    "                    tm_len = 20\n",
    "                \n",
    "                r_primer = revcom(r_temp_left[-tm_len:])\n",
    "                overhang_r = revcom(r_temp_right[0:rg_ind+24-len(r_temp_left)])\n",
    "                r_rule = 3\n",
    "\n",
    "            #Tm optimization\n",
    "            tm_flag = 0\n",
    "            while tm_flag == 0:\n",
    "                ta_tm_values = getTM(f_primer,r_primer)\n",
    "                if np.abs(ta_tm_values[0]-ta_tm_values[1]) > 2:\n",
    "                    tm_flag = 0\n",
    "                    tm_len = tm_len + 1 \n",
    "                    if ta_tm_values[0] - ta_tm_values[1] > 0:\n",
    "                        #elongation of r primer\n",
    "                        if r_rule == 1:\n",
    "                            r_primer = revcom(r_temp_left[rg_ind+24-tm_len:rg_ind+24])\n",
    "                        elif r_rule == 2:\n",
    "                            r_primer = revcom(r_temp_left[-tm_len:])\n",
    "                        elif r_rule == 3:\n",
    "                            r_primer = revcom(r_temp_left[-tm_len:])\n",
    "\n",
    "                    else:\n",
    "                        #elongation of f primer\n",
    "                        if f_rule == 1:\n",
    "                            f_primer = f_temp_right[0:tm_len]\n",
    "                        elif f_rule == 2:\n",
    "                            f_primer = f_temp_right[fg_ind:fg_ind+tm_len]\n",
    "                        elif f_rule == 3:\n",
    "                            f_primer = f_temp_right[0:tm_len]\n",
    "\n",
    "                else:\n",
    "                    tm_flag = 1\n",
    "                    cb_region = np.vstack((cb_region, [i, f_primer, r_primer, np.round(len(sequences[i])*(30/1000),2)]))\n",
    "\n",
    "            #Overhang addition\n",
    "            f_start = CntSubstr(cb_region[1][1], sequences[int(cb_region[1][0])])\n",
    "            f_end = len(sequences[int(cb_region[1][0])]) - CntSubstr(cb_region[1][2], revcom(sequences[int(cb_region[1][0])]))\n",
    "            PCR_primers = np.vstack((PCR_primers,[cb_region[1][0],overhang_f+cb_region[1][1],overhang_r+cb_region[1][2],cb_region[1][3], len(overhang_f)+len(overhang_r)+len(sequences[int(cb_region[1][0])][f_start:f_end])]))\n",
    "\n",
    "        #idt file\n",
    "        plasmid_name = snap_file.split('.')[0]\n",
    "        idt_sheet = []\n",
    "\n",
    "        for i in range(np.shape(final_guide)[0]):\n",
    "            if i == 0:\n",
    "                idt_name = plasmid_name + '_' + 'G1' + '_j' + str(len(sequences)) + '_' + str(i+1) \n",
    "                idt_sheet.append([idt_name,revcom(final_guide[i][1][0:16]),'25 nmole DNA Oligo','Standard Desalting','-','-'])\n",
    "\n",
    "                idt_name = plasmid_name + '_' + 'G2' + '_j' + str(len(sequences)) + '_' + str(i+1) \n",
    "                idt_sheet.append([idt_name,final_guide[i][1][8:24],'25 nmole DNA Oligo','Standard Desalting','-','-'])\n",
    "            else:\n",
    "                idt_name = plasmid_name + '_' + 'G1' + '_j' + str(i) + '_' + str(i+1) \n",
    "                idt_sheet.append([idt_name,revcom(final_guide[i][1][0:16]),'25 nmole DNA Oligo','Standard Desalting','-','-'])\n",
    "\n",
    "                idt_name = plasmid_name + '_' + 'G2' + '_j' + str(i) + '_' + str(i+1) \n",
    "                idt_sheet.append([idt_name,final_guide[i][1][8:24],'25 nmole DNA Oligo','Standard Desalting','-','-'])\n",
    "\n",
    "        for i in range(1,np.shape(PCR_primers)[0]):\n",
    "            idt_name = plasmid_name + '_' + 'FP' + '_' + str(int(PCR_primers[i][0])+1)\n",
    "            if len(PCR_primers[i][1]) < 60:\n",
    "                idt_sheet.append([idt_name, PCR_primers[i][1],'25 nmole DNA Oligo','Standard Desalting', PCR_primers[i][3], PCR_primers[i][4]])\n",
    "            else:\n",
    "                idt_sheet.append([idt_name, PCR_primers[i][1],'100 nmole DNA Oligo','Standard Desalting', PCR_primers[i][3], PCR_primers[i][4]])\n",
    "\n",
    "            idt_name = plasmid_name + '_' + 'RP' + '_' + str(int(PCR_primers[i][0])+1)\n",
    "            if len(PCR_primers[i][2]) < 60:\n",
    "                idt_sheet.append([idt_name, PCR_primers[i][2],'25 nmole DNA Oligo','Standard Desalting', PCR_primers[i][3], PCR_primers[i][4]])\n",
    "            else:\n",
    "                idt_sheet.append([idt_name, PCR_primers[i][2],'100 nmole DNA Oligo','Standard Desalting', PCR_primers[i][3], PCR_primers[i][4]])\n",
    "\n",
    "        if merge_flag == 1:\n",
    "            for i in range(1,np.shape(merging_primers)[0]):\n",
    "                idt_name = plasmid_name + '_' + 'EFP' + '_' + str(int(merging_primers[i][0])+1)\n",
    "                if len(merging_primers[i][1]) < 60:\n",
    "                    idt_sheet.append([idt_name, merging_primers[i][1],'25 nmole DNA Oligo','Standard Desalting', merging_primers[i][3], merging_primers[i][4]])\n",
    "                else:\n",
    "                    idt_sheet.append([idt_name, merging_primers[i][1],'100 nmole DNA Oligo','Standard Desalting', merging_primers[i][3], merging_primers[i][4]])\n",
    "\n",
    "                idt_name = plasmid_name + '_' + 'ERP' + '_' + str(int(merging_primers[i][0])+1)\n",
    "                if len(merging_primers[i][2]) < 60:\n",
    "                    idt_sheet.append([idt_name, merging_primers[i][2],'25 nmole DNA Oligo','Standard Desalting', merging_primers[i][3], merging_primers[i][4]])\n",
    "                else:\n",
    "                    idt_sheet.append([idt_name, merging_primers[i][2],'100 nmole DNA Oligo','Standard Desalting', merging_primers[i][3], merging_primers[i][4]])\n",
    "        \n",
    "        idt_sheet_df = pd.DataFrame(idt_sheet, columns =['Name','Sequence','Scale','Purification','Extension Time','Template Length'])\n",
    "            \n",
    "        df_index_to_delete = idt_sheet_df[idt_sheet_df.duplicated('Name', keep=False)]\n",
    "        df_index_to_delete.reset_index(inplace=True)\n",
    "        index_to_delete = []\n",
    "        for i in range(np.shape(df_index_to_delete)[0]):\n",
    "            if i%4 == 1 or i%4 == 2:\n",
    "                index_to_delete.append(df_index_to_delete['index'][i])\n",
    "\n",
    "        idt_sheet_df = idt_sheet_df.drop(index_to_delete).reset_index(drop = True)\n",
    "        idt_sheet_df.to_csv('Primers_Guides_primer3_'+snap_file.split('.')[0]+'.csv', index=False)\n",
    "        \n",
    "        for i in range(np.shape(sequences)[0]):\n",
    "            frag_name_rep = snap_file.split('.')[0] + '_f' + str(i+1)\n",
    "            frag_seq = sequences[i]\n",
    "            f_primer = idt_sheet_df['Sequence'][2*np.shape(sequences)[0]+2*i]\n",
    "            r_primer = idt_sheet_df['Sequence'][2*np.shape(sequences)[0]+2*i+1]\n",
    "\n",
    "            over_f_flag = 0\n",
    "            over_r_flag = 0\n",
    "\n",
    "            if f_primer in frag_seq:\n",
    "                over_f_flag = 0\n",
    "            else:\n",
    "                over_f_flag = 1\n",
    "\n",
    "            if revcom(r_primer) in frag_seq:\n",
    "                over_r_flag = 0\n",
    "            else:\n",
    "                over_r_flag = 1\n",
    "\n",
    "            if over_f_flag*over_r_flag == 1:\n",
    "                inter_frag_seq = reduce(lambda a, b: a + b[overlap(a,b):], [f_primer, frag_seq])\n",
    "                final_frag_seq = reduce(lambda a, b: a + b[overlap(a,b):], [inter_frag_seq, revcom(r_primer)])\n",
    "\n",
    "            elif over_f_flag == 1 and over_r_flag == 0:\n",
    "                inter_frag_seq = reduce(lambda a, b: a + b[overlap(a,b):], [f_primer, frag_seq])\n",
    "                final_frag_seq = inter_frag_seq[:inter_frag_seq.find(revcom(r_primer))] + revcom(r_primer)\n",
    "\n",
    "            elif over_f_flag == 0 and over_r_flag == 1:\n",
    "                inter_frag_seq = reduce(lambda a, b: a + b[overlap(a,b):], [frag_seq, revcom(r_primer)])\n",
    "                final_frag_seq = inter_frag_seq[inter_frag_seq.find(f_primer):]\n",
    "\n",
    "            else:\n",
    "                inter_frag_seq = frag_seq[frag_seq.find(f_primer):]\n",
    "                final_frag_seq = inter_frag_seq[:inter_frag_seq.find(revcom(r_primer))] + revcom(r_primer)\n",
    "\n",
    "            final_fragments.append([frag_name_rep, final_frag_seq])\n",
    "            \n",
    "        for i in range(len(pre_sequences)-len(sequences)-len(index_to_delete)):\n",
    "            f_primer_1 = idt_sheet_df['Sequence'][4*np.shape(sequences)[0]+4*i]\n",
    "            r_primer_1 = idt_sheet_df['Sequence'][4*np.shape(sequences)[0]+4*i+1]\n",
    "            frag_seq_1 = pre_sequences[int(idt_sheet_df['Name'][4*np.shape(sequences)[0]+4*i].split('EFP_')[1])-1]\n",
    "            final_frag_seq_1 = reduce(lambda a, b: a + b[overlap(a,b):], [f_primer_1, frag_seq_1, revcom(r_primer_1)])\n",
    "            final_name_1 = idt_sheet_df['Name'][4*np.shape(sequences)[0]+4*i].split('_')[0] + '_Ext_PCR_f' + idt_sheet_df['Name'][4*np.shape(sequences)[0]+4*i].split('EFP_')[1]\n",
    "\n",
    "            final_interm_fragments.append([final_name_1, final_frag_seq_1])\n",
    "\n",
    "            f_primer_2 = idt_sheet_df['Sequence'][4*np.shape(sequences)[0]+4*i+2]\n",
    "            r_primer_2 = idt_sheet_df['Sequence'][4*np.shape(sequences)[0]+4*i+3]\n",
    "            frag_seq_2 = pre_sequences[int(idt_sheet_df['Name'][4*np.shape(sequences)[0]+4*i+2].split('EFP_')[1])-1]\n",
    "            final_frag_seq_2 = reduce(lambda a, b: a + b[overlap(a,b):], [f_primer_2, frag_seq_2, revcom(r_primer_2)])\n",
    "            final_name_2 = idt_sheet_df['Name'][4*np.shape(sequences)[0]+4*i].split('_')[0] + '_Ext_PCR_f' + idt_sheet_df['Name'][4*np.shape(sequences)[0]+4*i+2].split('EFP_')[1]\n",
    "\n",
    "            final_interm_fragments.append([final_name_2, final_frag_seq_2])\n",
    "\n",
    "        pre_verify_re = np.array(['enzyme name','recognition sequence','cut_index','frequency'])\n",
    "        for re_i in range(np.shape(re_site)[0]):\n",
    "            curr_re_seq = re_site[re_i,0]\n",
    "            re_frequency = len([m.start() for m in re.finditer(curr_re_seq, re_plasmid_seq)])\n",
    "            pre_verify_re = np.vstack((pre_verify_re,[re_site[re_i,3],curr_re_seq,re_site[re_i,2],re_frequency]))    \n",
    "\n",
    "        verify_re = pre_verify_re[0,:]\n",
    "        for i in range(1,np.shape(pre_verify_re)[0]):\n",
    "            if pre_verify_re[i,3] != '0':\n",
    "                verify_re = np.vstack((verify_re,pre_verify_re[i,:]))\n",
    "\n",
    "        length_comb = 4 #int(input(\"Enter number of restriction enzymes you want to use: [Higher number recommended for smaller plasmid]\" + \"Enter a number less than \" + str(np.shape(verify_re)[0]) +\":\"))\n",
    "        re_final = ['RE combination','Band Size']   \n",
    "        comb_to_explore = np.arange(length_comb)\n",
    "        for p in range(len(comb_to_explore)):\n",
    "            re_options = []\n",
    "            re_found = False\n",
    "            for re_opt_i in itertools.combinations(verify_re[1:,0],p+1):\n",
    "                re_options.append(np.asarray(re_opt_i))\n",
    "\n",
    "            re_gel_comb = []\n",
    "            for l in range(p+1):\n",
    "                re_gel_comb.append('RE'+ str(l+1))\n",
    "\n",
    "            re_gel_comb.append('band sizes')\n",
    "            for i in range(np.shape(re_options)[0]):\n",
    "                re_names = re_options[i]\n",
    "                locations = []\n",
    "                for j in range(len(re_names)):\n",
    "                    index = np.where(verify_re[:,0] == re_options[i][j])[0][0]\n",
    "                    matches = re.finditer(verify_re[index,1], re_plasmid_seq)\n",
    "                    locations.append([match.start() for match in matches])\n",
    "\n",
    "                re_locations = locations[0]\n",
    "                if len(locations) > 1:\n",
    "                    for m in range(len(locations)-1):\n",
    "                        re_locations = np.concatenate([re_locations,locations[m+1]])\n",
    "\n",
    "                re_locations = np.sort(re_locations)\n",
    "                band_size = []\n",
    "                for j in range(len(re_locations)):\n",
    "                    if j == len(re_locations) - 1:\n",
    "                        band_size.append(len(plasmid_seq)-re_locations[j]+re_locations[0])\n",
    "                    else:\n",
    "                        band_size.append(re_locations[j+1]-re_locations[j])\n",
    "\n",
    "                if band_filter(np.sort(band_size)):\n",
    "                    re_found = True\n",
    "                    if len(band_size) > 1:\n",
    "                        band_size_trans = str(';'.join(str(v) for v in list(np.sort(band_size))))\n",
    "                        re_gel_comb = np.vstack((re_gel_comb,np.concatenate([re_names,[band_size_trans]])))\n",
    "\n",
    "            if np.array(re_gel_comb).ndim > 1:\n",
    "                for m in range(np.shape(re_gel_comb)[0]-1):\n",
    "                    curr_re_comb = ''\n",
    "                    for k in range(p+1):\n",
    "                        curr_re_comb = curr_re_comb + re_gel_comb[m+1,k] + ', '\n",
    "\n",
    "                    re_final = np.vstack((re_final,[curr_re_comb[:-2],re_gel_comb[m+1,np.shape(re_gel_comb)[1]-1]]))\n",
    "\n",
    "            if p == len(comb_to_explore)-1:\n",
    "                final_re_df = pd.DataFrame(re_final)\n",
    "                if final_re_count == 0:\n",
    "                    common_final_re_df = final_re_df[1:]\n",
    "                else:\n",
    "                    common_final_re_df = pd.merge(common_final_re_df, final_re_df[1:], how='inner', on = 0)\n",
    "\n",
    "                final_re_count = 1\n",
    "                common_final_re_df_index.append(snap_file.split('.')[0])\n",
    "\n",
    "if working_plasmid_count > 0:\n",
    "    common_final_re_df.columns = common_final_re_df_index\n",
    "    common_final_re_df.to_csv('Combined_RE_for_verification'+'.csv', index=False)\n",
    "\n",
    "    final_frag_df = pd.DataFrame(final_fragments, columns = ['name', 'seq']).groupby('seq')['name'].apply(lambda x: x.unique()).reset_index()\n",
    "    final_frag_df[final_frag_df['name'].map(len) > 1]['name'].reset_index(drop=True).to_csv('Repeated_Fragments'+'.csv', index=True)\n",
    "\n",
    "    interm_df = pd.DataFrame(final_interm_fragments, columns = ['name', 'seq']).groupby('seq')['name'].apply(lambda x: x.unique()).reset_index()\n",
    "    interm_df[interm_df['name'].map(len) > 1]['name'].reset_index(drop=True).to_csv('ext_PCR_Repeated_Fragments'+'.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
